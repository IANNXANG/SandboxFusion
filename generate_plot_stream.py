import openai
import re
import os
import requests
import json
import base64


# è®¾ç½®æ€è€ƒæ¨¡å¼å‚æ•°
enable_thinking = False
#enable_thinking = True

def run_code_in_sandbox(code, png_filename):
    """
    åœ¨æ²™ç›’ä¸­æ‰§è¡Œä»£ç å¹¶ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶
    
    Args:
        code (str): è¦æ‰§è¡Œçš„Pythonä»£ç 
        png_filename (str): æœŸæœ›ç”Ÿæˆçš„PNGæ–‡ä»¶å
    
    Returns:
        tuple: (success, local_filename, result_info)
            success: æ˜¯å¦æˆåŠŸ
            local_filename: æœ¬åœ°ä¿å­˜çš„æ–‡ä»¶åï¼ˆå¦‚æœæˆåŠŸï¼‰
            result_info: è¯¦ç»†çš„æ‰§è¡Œç»“æœä¿¡æ¯
    """
    try:
        print("\næ­£åœ¨é€šè¿‡æ²™ç›’æ‰§è¡Œç”Ÿæˆçš„ä»£ç ...")
        
        # å‘é€è¯·æ±‚åˆ°æ²™ç›’API
        sandbox_response = requests.post('http://localhost:8080/run_code', json={
            'code': code,
            'language': 'python',
            'fetch_files': [png_filename]  # æŒ‡å®šè¦è·å–çš„å›¾ç‰‡æ–‡ä»¶
        })
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if sandbox_response.status_code == 200:
            result = sandbox_response.json()
            
            # æ‰“å°å®Œæ•´çš„æ²™ç›’æ‰§è¡Œç»“æœï¼ˆçœç•¥è¿‡é•¿çš„base64å­—ç¬¦ä¸²ï¼‰
            print("\n=== æ²™ç›’å®Œæ•´æ‰§è¡Œç»“æœ ===")
            
            # åˆ›å»ºç»“æœå‰¯æœ¬ç”¨äºæ˜¾ç¤ºï¼Œçœç•¥è¿‡é•¿çš„base64å­—ç¬¦ä¸²
            display_result = result.copy()
            if 'files' in display_result:
                display_files = {}
                for filename, content in display_result['files'].items():
                        display_files[filename] = "base64 str"
                display_result['files'] = display_files
            
            print(json.dumps(display_result, indent=2, ensure_ascii=False))
            print("=" * 30)
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–åˆ°æ–‡ä»¶
            if 'files' in result and png_filename in result['files']:
                # è§£ç base64å›¾ç‰‡æ•°æ®
                image_data = base64.b64decode(result['files'][png_filename])
                
                # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
                local_filename = f"downloaded_{png_filename}"
                with open(local_filename, 'wb') as f:
                    f.write(image_data)
                
                # æ·»åŠ æœ¬åœ°æ–‡ä»¶ä¿¡æ¯åˆ°display_result
                display_result['local_filename'] = local_filename
                display_result['image_size'] = len(image_data)
                
                success_info = {
                    'status': 'success',
                    'local_filename': local_filename,
                    'image_size': len(image_data),
                    'execution_result': result,
                    'display_result': display_result
                }
                
                print(f"\nâœ… å›¾ç‰‡å·²æˆåŠŸä»æ²™ç›’è·å–å¹¶ä¿å­˜ä¸º: {local_filename}")
                
                return True, local_filename, success_info
            else:
                error_info = {
                    'status': 'file_not_found',
                    'message': 'æœªèƒ½ä»æ²™ç›’è·å–åˆ°å›¾ç‰‡æ–‡ä»¶',
                    'execution_result': result
                }
                
                print("âŒ æœªèƒ½ä»æ²™ç›’è·å–åˆ°å›¾ç‰‡æ–‡ä»¶")
                if 'run_result' in result:
                    print("æ‰§è¡Œç»“æœ:", result['run_result'])
                
                return False, None, error_info
        else:
            error_info = {
                'status': 'api_error',
                'status_code': sandbox_response.status_code,
                'response_text': sandbox_response.text
            }
            
            print(f"âŒ æ²™ç›’APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {sandbox_response.status_code}")
            print("å“åº”å†…å®¹:", sandbox_response.text)
            
            return False, None, error_info
            
    except Exception as e:
        error_info = {
            'status': 'exception',
            'error': str(e)
        }
        
        print(f"\nè°ƒç”¨æ²™ç›’APIæ—¶å‡ºé”™: {e}")
        return False, None, error_info

# é…ç½®OpenAIå®¢æˆ·ç«¯è¿æ¥åˆ°æœ¬åœ°vllmæœåŠ¡
client = openai.OpenAI(
    base_url="http://localhost:8001/v1",
    api_key="dummy-key" 
)


# æ ¹æ®æ€è€ƒæ¨¡å¼è®¾ç½®ä¸åŒçš„å‚æ•°
if enable_thinking:
    # æ€è€ƒæ¨¡å¼å‚æ•°
    temperature = 0.6
    top_p = 0.95
    top_k = 20
    min_p = 0.0
    max_token = 20480
else:
    # éæ€è€ƒæ¨¡å¼å‚æ•°
    temperature = 0.7
    top_p = 0.8
    top_k = 20
    min_p = 0.0
    max_token = 20480

# æ„å»ºsystemå’Œuser prompt
system_prompt = """
è¯·ç”Ÿæˆä¸€æ®µPythonä»£ç ã€‚

è¦æ±‚ï¼š
1. ä»£ç éœ€è¦æ”¾åœ¨<code>å’Œ</code>æ ‡ç­¾ä¸­
2. ä¿å­˜çš„PNGæ–‡ä»¶åéœ€è¦æ”¾åœ¨<png>å’Œ</png>æ ‡ç­¾ä¸­
3. ä»£ç åº”è¯¥æ˜¯å®Œæ•´å¯æ‰§è¡Œçš„
4. å›¾ç‰‡ä¸Šæ‰€æœ‰æ–‡å­—éƒ½åº”è¯¥æ˜¯è‹±æ–‡
5. ç»˜å›¾ç¾è§‚ï¼Œè¿™æ˜¯ä¸€ä¸ªå­¦æœ¯æŠ¥å‘Šçš„æ’å›¾

ç¤ºä¾‹æ ¼å¼ï¼š
<code>
import matplotlib.pyplot as plt
# ä½ çš„ç»˜å›¾ä»£ç 
plt.savefig('filename.png')
</code>

<png>filename.png</png>
"""

user_prompt = """ä½ æ˜¯ä¸€åæ•°æ®åˆ†æå¸ˆï¼Œéœ€è¦å¯¹ä»¥ä¸‹ä¸€ç»„é”€å”®æ•°æ®è¿›è¡Œåˆ†æå¹¶ç”ŸæˆæŠ¥å‘Šåˆ†æä»£ç ã€‚æ•°æ®æ¶µç›–äº†æŸå…¬å¸è¿‡å» 12 ä¸ªæœˆï¼ˆ2024 å¹´ 1 æœˆ - 2024 å¹´ 12 æœˆï¼‰çš„äº§å“é”€å”®ä¿¡æ¯ï¼Œå…·ä½“å­—æ®µåŠæ•°æ®å¦‚ä¸‹ï¼š

æœˆä»½	äº§å“ A é”€é‡ï¼ˆä»¶ï¼‰	äº§å“ B é”€é‡ï¼ˆä»¶ï¼‰	äº§å“ A é”€å”®é¢ï¼ˆå…ƒï¼‰	äº§å“ B é”€å”®é¢ï¼ˆå…ƒï¼‰	é”€å”®åœ°åŒº	å®¢æˆ·æ»¡æ„åº¦è¯„åˆ†ï¼ˆæ»¡åˆ† 10 åˆ†ï¼‰
2024 å¹´ 1 æœˆ	120	80	12000	8000	ååŒ—	8.5
2024 å¹´ 2 æœˆ	130	75	13500	7500	ååŒ—	8.2
2024 å¹´ 3 æœˆ	150	90	15000	9000	ååŒ—	8.8
2024 å¹´ 4 æœˆ	140	85	14000	8500	åä¸œ	9.0
2024 å¹´ 5 æœˆ	160	95	16000	9500	åä¸œ	8.9
2024 å¹´ 6 æœˆ	145	88	14500	8800	åä¸œ	9.2
2024 å¹´ 7 æœˆ	135	78	13500	7800	åå—	8.0
2024 å¹´ 8 æœˆ	125	82	12500	8200	åå—	8.3
2024 å¹´ 9 æœˆ	142	92	14200	9200	åå—	8.6
2024 å¹´ 10 æœˆ	155	100	15500	10000	åä¸­	9.5
2024 å¹´ 11 æœˆ	165	105	16500	10500	åä¸­	9.3
2024 å¹´ 12 æœˆ	170	110	17000	11000	åä¸­	9.6
ä½¿ç”¨matplotlibåº“åˆ›å»ºä¸€ä¸ªåˆé€‚çš„å›¾å¹¶ä¿å­˜ä¸ºPNGæ–‡ä»¶
"""
#user_prompt = "ä½¿ç”¨matplotlibåº“åˆ›å»ºä¸€ä¸ªæ­£å¼¦æ›²çº¿å¹¶ä¿å­˜ä¸ºPNGæ–‡ä»¶"


def stream_generate_with_tool_calling():
    """
    æµå¼ç”Ÿæˆï¼Œå½“æ£€æµ‹åˆ°</png>æ—¶åœæ­¢ç”Ÿæˆå¹¶æ‰§è¡Œæ²™ç›’ä»£ç ï¼Œç„¶åç»§ç»­ç”Ÿæˆ
    """
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
    
    accumulated_response = ""
    png_detected = False
    
    while True:
        print(f"\n=== å¼€å§‹ç”Ÿæˆï¼ˆå½“å‰æ¶ˆæ¯æ•°: {len(messages)}ï¼‰===")
        
        # æµå¼è°ƒç”¨æ¨¡å‹
        stream = client.chat.completions.create(
            model="8001vllm",
            messages=messages,
            max_tokens=max_token,
            temperature=temperature,
            top_p=top_p,
            stream=True,
            extra_body={
                "top_k": top_k,
                "min_p": min_p,
                "chat_template_kwargs": {"enable_thinking": enable_thinking}
            }
        )
        
        current_chunk = ""
        
        # å¤„ç†æµå¼å“åº”
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                current_chunk += content
                accumulated_response += content
                
                # å®æ—¶æ‰“å°ç”Ÿæˆçš„å†…å®¹
                print(content, end='', flush=True)
                
                # æ£€æµ‹æ˜¯å¦å‡ºç°äº†</png>
                if '</png>' in current_chunk:
                    png_detected = True
                    print("\n\nğŸ” æ£€æµ‹åˆ°</png>æ ‡ç­¾ï¼Œåœæ­¢ç”Ÿæˆ...")
                    break
        
        print("\n" + "="*50)
        
        # å¦‚æœæ£€æµ‹åˆ°</png>ï¼Œæ‰§è¡Œæ²™ç›’ä»£ç 
        if png_detected:
            
            # æå–ä»£ç å’Œæ–‡ä»¶å
            think_pattern = r'<think>.*?</think>'
            filtered_response = re.sub(think_pattern, '', accumulated_response, flags=re.DOTALL)
            
            code_pattern = r'<code>(.*?)</code>'
            code_matches = re.findall(code_pattern, filtered_response, re.DOTALL)
            
            png_pattern = r'<png>(.*?)</png>'
            png_matches = re.findall(png_pattern, filtered_response, re.DOTALL)
            
            if code_matches and png_matches:
                code = code_matches[-1].strip()  # å–æœ€åä¸€ä¸ªåŒ¹é…
                png_filename = png_matches[-1].strip()  # å–æœ€åä¸€ä¸ªåŒ¹é…
                
                print(f"\nğŸ“ æå–åˆ°çš„ä»£ç :")
                print(code)
                print(f"\nğŸ–¼ï¸ æå–åˆ°çš„PNGæ–‡ä»¶å: {png_filename}")
                
                # æ‰§è¡Œæ²™ç›’ä»£ç 
                success, local_filename, result_info = run_code_in_sandbox(code, png_filename)
                
                # ç›´æ¥ä½¿ç”¨å‡½æ•°è¿”å›çš„display_resultä½œä¸ºå·¥å…·è¿”å›å€¼
                if success:
                    tool_result = json.dumps(result_info['display_result'], indent=2, ensure_ascii=False)
                else:
                    tool_result = json.dumps(result_info, indent=2, ensure_ascii=False)
                
                # å°†åŠ©æ‰‹çš„å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²ï¼ˆè¿‡æ»¤æ‰thinkæ ‡ç­¾å†…å®¹ï¼‰
                # è¿‡æ»¤thinkæ ‡ç­¾å†…å®¹
                think_pattern = r'<think>.*?</think>'
                filtered_assistant_response = re.sub(think_pattern, '', accumulated_response, flags=re.DOTALL)
                messages.append({"role": "assistant", "content": filtered_assistant_response})
                messages.append({
                    "role": "user", 
                    "content": f"""[å·¥å…·æ‰§è¡Œç»“æœ]
{tool_result}

è¯·æ ¹æ®æ‰§è¡Œç»“æœç»§ç»­å›å¤ã€‚å¦‚æœæ‰§è¡ŒæˆåŠŸï¼Œè¯·æ€»ç»“ä»»åŠ¡å®Œæˆæƒ…å†µï¼›å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè¯·åˆ†æåŸå› å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚"""
                })
                
                # é‡ç½®çŠ¶æ€ï¼Œå‡†å¤‡ç»§ç»­ç”Ÿæˆ
                accumulated_response = ""
                png_detected = False
                
                print(f"\nğŸ”„ å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»§ç»­ç”Ÿæˆ...")
                continue
            else:
                print("\nâŒ æœªèƒ½ä»å“åº”ä¸­æå–åˆ°å®Œæ•´çš„ä»£ç å’Œæ–‡ä»¶å")
                break
        else:
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°</png>ï¼Œè¯´æ˜ç”Ÿæˆå®Œæˆ
            print("\nâœ… ç”Ÿæˆå®Œæˆï¼Œæœªæ£€æµ‹åˆ°æ–°çš„</png>æ ‡ç­¾")
            break
    
    # è¿‡æ»¤æœ€ç»ˆå“åº”ä¸­çš„thinkæ ‡ç­¾å†…å®¹
    think_pattern = r'<think>.*?</think>'
    final_filtered_response = re.sub(think_pattern, '', accumulated_response, flags=re.DOTALL)
    
    # å°†æœ€ç»ˆçš„åŠ©æ‰‹å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²ä¸­
    if final_filtered_response.strip():  # åªæœ‰å½“å“åº”ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ 
        messages.append({"role": "assistant", "content": final_filtered_response})
    
    return  messages

# æ‰§è¡Œæµå¼ç”Ÿæˆ
messages = stream_generate_with_tool_calling()

# æ‰“å°å®Œæ•´çš„å¯¹è¯å†å²ï¼ˆåŒ…æ‹¬æœ€ç»ˆå“åº”ï¼‰
print("\n" + "="*60)
print("ğŸ“‹ å®Œæ•´å¯¹è¯å†å²:")
print("="*60)
for i, message in enumerate(messages):
    print(f"\n[æ¶ˆæ¯ {i+1}] è§’è‰²: {message['role']}")
    print(f"å†…å®¹é•¿åº¦: {len(message['content'])} å­—ç¬¦")
    print("-" * 40)
    # ç›´æ¥æ‰“å°å†…å®¹ï¼Œä¸è¿›è¡Œé¢å¤–çš„è½¬ä¹‰å¤„ç†
    print(message['content'])
    print("-" * 40)
print("\n" + "="*60)